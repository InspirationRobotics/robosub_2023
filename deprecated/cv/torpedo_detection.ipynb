{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bc518ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hellow\n"
     ]
    }
   ],
   "source": [
    "print(\"hellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78545580",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 14\u001b[0m\n\u001b[0;32m     10\u001b[0m gray\u001b[38;5;241m=\u001b[39mcv2\u001b[38;5;241m.\u001b[39mcvtColor(frame,cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     12\u001b[0m gray_blurred \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mblur(gray, (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n\u001b[1;32m---> 14\u001b[0m detected_circles \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHoughCircles\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgray_blurred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHOUGH_GRADIENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam1\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m               \u001b[49m\u001b[43mparam2\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mminRadius\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmaxRadius\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m40\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m detected_circles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m \n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# Convert the circle parameters a, b and r to integers.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     detected_circles \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39muint16(np\u001b[38;5;241m.\u001b[39maround(detected_circles))\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cap = cv2.VideoCapture('front_torpidoes_vampire_2_provider_vision_Front_GigE_compressed.mp4')\n",
    "#code cannot detect ellipses or color\n",
    "while 1: \n",
    "    ret,frame =cap.read() \n",
    "#     cascade=cv2.CascadeClassifier(\"cascade.xml\")\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    gray_blurred = cv2.blur(gray, (3, 3))\n",
    "    \n",
    "    detected_circles = cv2.HoughCircles(gray_blurred, \n",
    "                       cv2.HOUGH_GRADIENT, 1, 20, param1 = 50,\n",
    "                   param2 = 30, minRadius = 1, maxRadius = 40)\n",
    "    \n",
    "    if detected_circles is not None:\n",
    "\n",
    "        # Convert the circle parameters a, b and r to integers.\n",
    "        detected_circles = np.uint16(np.around(detected_circles))\n",
    "\n",
    "        for pt in detected_circles[0, :]:\n",
    "            a, b, r = pt[0], pt[1], pt[2]\n",
    "\n",
    "            # Draw the circumference of the circle.\n",
    "            cv2.circle(frame, (a, b), r, (0, 255, 0), 2)\n",
    "\n",
    "            # Draw a small circle (of radius 1) to show the center.\n",
    "            cv2.circle(frame, (a, b), 1, (0, 0, 255), 3)\n",
    "        \n",
    "#     _, threshold = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)\n",
    "  \n",
    "#     # using a findContours() function\n",
    "#     contours, _ = cv2.findContours(\n",
    "#         threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "#     for contour in contours:\n",
    "  \n",
    "#         # here we are ignoring first counter because \n",
    "#         area = cv2.contourArea(contour)\n",
    "\n",
    "#         # cv2.approxPloyDP() function to approximate the shape\n",
    "#         approx = cv2.approxPolyDP(\n",
    "#             contour, 0.01 * cv2.arcLength(contour, True), True)\n",
    "\n",
    "#         M = cv2.moments(contour)\n",
    "#         if M['m00'] != 0.0:\n",
    "#             x = int(M['m10']/M['m00'])\n",
    "#             y = int(M['m01']/M['m00'])\n",
    "\n",
    "#         if (area>20000):\n",
    "#             cv2.drawContours(frame, [contour], 0, (0, 0, 255), 5)\n",
    "#             cv2.putText(frame, 'Quadrilateral', (x, y),\n",
    "#                         cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "                \n",
    "    cv2.imshow('Resized', frame)\n",
    "\n",
    "      \n",
    "    if cv2.waitKey(1)==27:\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "  \n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "58f22262",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import img_to_array, load_img\n",
    "   \n",
    "# Initialising the ImageDataGenerator class.\n",
    "# We will pass in the augmentation parameters in the constructor.\n",
    "datagen = ImageDataGenerator(\n",
    "        rotation_range = 30,\n",
    "        shear_range = 0.2,\n",
    "        zoom_range = 0.2,\n",
    "        horizontal_flip = True,\n",
    "        brightness_range = (0.5, 1.5))\n",
    "    \n",
    "# Loading a sample image \n",
    "img = load_img('image9.png') \n",
    "# Converting the input sample image to an array\n",
    "x = img_to_array(img)\n",
    "# Reshaping the input image\n",
    "x = x.reshape((1, ) + x.shape) \n",
    "   \n",
    "# Generating and saving 5 augmented samples \n",
    "# using the above defined parameters. \n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size = 1,\n",
    "    save_to_dir ='aug_img', \n",
    "    save_prefix ='image', save_format ='jpeg'):\n",
    "    i += 1\n",
    "    if i > 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f3a95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
